# llm_agents/agents/exploiter.py

from typing import Dict, List
from openai import OpenAI
import os
import json
import re
from jsonschema import validate, ValidationError
from utils.print_utils import create_progress_spinner, print_warning
from utils.langsmith_tracing import trace_agent_call

# Define JSON schema for exploit plans
EXPLOIT_SCHEMA = {
    "type": "object",
    "properties": {
        "plan": {
            "type": "object",
            "properties": {
                "setup_steps": {"type": "array", "items": {"type": "string"}},
                "execution_steps": {"type": "array", "items": {"type": "string"}},
                "validation_steps": {"type": "array", "items": {"type": "string"}},
            },
            "required": ["setup_steps", "execution_steps", "validation_steps"],
        }
    },
    "required": ["plan"],
}


class ExploiterAgent:
    def __init__(self, model_config=None):
        from ..config import ModelConfig

        self.model_config = model_config or ModelConfig()
        self.model_name = self.model_config.get_model("exploiter")

        # Get provider info for the selected model
        _, api_key_env, _ = self.model_config.get_provider_info(self.model_name)

        # Initialize OpenAI client with the correct settings
        self.client = OpenAI(
            api_key=os.getenv(api_key_env),
            **self.model_config.get_openai_args(self.model_name)
        )

    def generate_exploit_plan(self, vulnerability_info: Dict) -> Dict:
        with create_progress_spinner("Generating exploit plan") as progress:
            task = progress.add_task("Analyzing vulnerability...")

            system_prompt = """You are a smart contract security educator specializing in creating educational proof-of-concept demonstrations for security training purposes. Your goal is to help developers understand vulnerabilities through hypothetical scenarios that illustrate security concepts.

These educational demonstrations are PURELY FOR LEARNING PURPOSES and would only be run in controlled test environments, never against real systems. Your explanations help security researchers and developers understand defensive coding practices.

Create educational scenarios that illustrate the theoretical concepts with MINIMUM steps needed to demonstrate the principle. You MUST provide your output in the exact JSON format requested, with no additional markdown formatting or explanations."""
            prompt = self._construct_exploit_prompt(vulnerability_info)

            progress.update(task, description="Generating plan...")
            # Call LLM
            response_text = self._call_llm(system_prompt, prompt)

            progress.update(task, description="Processing response...")
            exploit_plan = self._parse_exploit_response(response_text)

            progress.update(task, completed=True)

        return {"exploit_plan": exploit_plan}

    def _construct_exploit_prompt(self, vulnerability_info: Dict) -> str:
        """
        Constructs the prompt for the LLM based on vulnerability information.

        Args:
            vulnerability_info (Dict): Information about the detected vulnerability.

        Returns:
            str: The constructed prompt.
        """
        prompt = f"""
                Analyze the following potential smart contract vulnerability and create an EDUCATIONAL demonstration plan to help developers understand the security concept. This is FOR EDUCATIONAL PURPOSES ONLY in a controlled test environment.

                Vulnerability Type: {vulnerability_info.get('vulnerability_type', 'N/A')}
                Confidence Score: {vulnerability_info.get('confidence_score', 'N/A')}
                Reasoning: {vulnerability_info.get('reasoning', 'N/A')}
                Affected Functions: {', '.join(vulnerability_info.get('affected_functions', []))}
                Code Snippet: {vulnerability_info.get('code_snippet', 'N/A')}

                Your educational demonstration should:
                1. CLEARLY ILLUSTRATE the vulnerability concept
                2. Be SIMPLE and FOCUSED on the educational principle
                3. Include SPECIFIC CODE EXAMPLES where helpful
                4. Be MINIMAL - use the fewest steps needed to demonstrate the concept

                If you determine the potential issue is NOT a genuine vulnerability, provide educational steps that demonstrate WHY it's not problematic.

                IMPORTANT: You MUST provide the exploit plan in EXACTLY this JSON format with NO additional text:

                {{
                    "plan": {{
                        "setup_steps": [
                            "Step 1: Create a test environment that demonstrates the vulnerability",
                            "Step 2: Prepare necessary contracts and accounts for the demonstration"
                        ],
                        "execution_steps": [
                            "Step 1: Demonstrate the normal contract behavior",
                            "Step 2: Demonstrate how the vulnerability could theoretically be triggered"
                        ],
                        "validation_steps": [
                            "Step 1: Explain what security principle was violated",
                            "Step 2: Show how developers can fix this vulnerability"
                        ]
                    }}
                }}

                DO NOT include any markdown formatting, explanations, or other text outside of this JSON structure.
                """
        return prompt

    def _parse_exploit_response(self, response: str) -> Dict:
        # Try to parse direct JSON first
        try:
            parsed_response = json.loads(response)
            validate(instance=parsed_response, schema=EXPLOIT_SCHEMA)
            return parsed_response.get("plan", {})
        except (json.JSONDecodeError, ValidationError):
            print_warning("Failed to parse exploit plan - trying to extract from markdown")

            # Try to find JSON in code blocks with multiple patterns
            json_patterns = [
                r"```json\s+(.*?)\s+```",  # JSON code block
                r"```\s+(\{.*?\})\s+```",  # Generic code block with JSON
                r"\{[\s\S]*\"plan\"[\s\S]*\}"  # Any JSON-like structure with "plan"
            ]

            for pattern in json_patterns:
                if match := re.search(pattern, response, re.DOTALL):
                    try:
                        # Clean up the extracted JSON string
                        json_str = match.group(1).strip()
                        # Remove any leading backticks or trailing backticks missed by the regex
                        json_str = re.sub(r'^```|```$', '', json_str)
                        # Remove excessive whitespace
                        json_str = re.sub(r'\n\s+', ' ', json_str)

                        parsed_response = json.loads(json_str)
                        validate(instance=parsed_response, schema=EXPLOIT_SCHEMA)
                        return parsed_response.get("plan", {})
                    except Exception as e:
                        continue  # Try the next pattern

            # If no valid JSON found, try to extract the plan format manually
            try:
                # Look for section headers that might indicate steps
                setup_steps = self._extract_steps(response, ["setup", "preparation", "configure"])
                execution_steps = self._extract_steps(response, ["execution", "exploit", "attack"])
                validation_steps = self._extract_steps(response, ["validation", "verify", "confirm"])

                # If we found steps in at least one section, use them
                if setup_steps or execution_steps or validation_steps:
                    return {
                        "setup_steps": setup_steps,
                        "execution_steps": execution_steps,
                        "validation_steps": validation_steps
                    }
            except Exception:
                pass

            print_warning("Failed to parse exploit plan structure")
            return {"setup_steps": [], "execution_steps": [], "validation_steps": []}

    def _extract_steps(self, text: str, section_keywords: List[str]) -> List[str]:
        """Extract steps from a section in the text based on keywords."""
        steps = []

        # Try to find sections with the specified keywords
        pattern = r'(?i)(?:' + '|'.join(section_keywords) + r')[^\n]*?\:?\n(.*?)(?:\n\s*\n|\n\s*(?:[A-Z][a-z]+)|$)'
        match = re.search(pattern, text, re.DOTALL)

        if match:
            section_text = match.group(1).strip()
            # Look for numbered or bulleted list items
            step_pattern = r'(?:^|\n)\s*(?:\d+\.|\-|\*|\•)\s*(.+?)(?=$|\n\s*(?:\d+\.|\-|\*|\•)|\n\s*\n)'
            step_matches = re.finditer(step_pattern, section_text, re.DOTALL)

            for step_match in step_matches:
                step = step_match.group(1).strip()
                if step:
                    steps.append(step)

            # If no list items found, try paragraphs
            if not steps:
                paragraphs = re.split(r'\n\s*\n', section_text)
                steps = [p.strip() for p in paragraphs if p.strip()]

        return steps

    @trace_agent_call("exploiter")
    def _call_llm(self, system_prompt: str, user_prompt: str) -> str:
        """
        Call LLM with appropriate message structure based on model type.
        """
        # Import token tracker
        from utils.token_tracker import token_tracker

        # Prepare appropriate messages based on model capabilities
        if self.model_config.supports_reasoning(self.model_name):
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
        else:
            messages = [
                {"role": "user", "content": system_prompt + user_prompt}
            ]

        if self.model_name == "claude-3-7-sonnet-latest":
            resp = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_tokens=64000,
                extra_body={ "thinking": { "type": "enabled", "budget_tokens": 2000 } },
            )
        else:
            resp = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages
            )

        # Track token usage
        if hasattr(resp, 'usage') and resp.usage:
            token_tracker.log_tokens(
                agent_name="exploiter",
                model_name=self.model_name,
                prompt_tokens=resp.usage.prompt_tokens,
                completion_tokens=resp.usage.completion_tokens,
                total_tokens=resp.usage.total_tokens
            )

        return resp.choices[0].message.content
